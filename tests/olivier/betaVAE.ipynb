{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# title : betaVAE.py\n",
    "# Author : Olivier Makuch\n",
    "# Date   : 2024-11-20\n",
    "# Purpose: Extract stock embeddings to test portfolio diversity\n",
    "# ==============================================================================\n",
    "\n",
    "# ==============================================================================\n",
    "# Load libraries\n",
    "# ==============================================================================\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom Classes\n",
    "from src.beta_vae import Encoder\n",
    "from src.beta_vae import Decoder\n",
    "from src.beta_vae import BetaVAE\n",
    "\n",
    "# Custom Functions\n",
    "from src.beta_vae import create_data_loaders\n",
    "from src.beta_vae import objective\n",
    "from src.beta_vae import train_beta_vae\n",
    "from src.beta_vae import get_embeddings\n",
    "from src.data_fetching import scrape_sp500_wikipedia\n",
    "from src.data_fetching import fetch_stock_data\n",
    "from src.data_fetching import prepare_data_for_vae\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching stock data...:  48%|████▊     | 244/505 [01:46<01:49,  2.39it/s]SW: Period '1y' is invalid, must be one of ['1d', '5d', '1mo', '3mo', '6mo', 'ytd', 'max']\n",
      "Fetching stock data...:  75%|███████▍  | 378/505 [02:44<00:55,  2.30it/s]AMTM: Period '1y' is invalid, must be one of ['1d', '5d', '1mo', '3mo', 'ytd', 'max']\n",
      "Fetching stock data...:  83%|████████▎ | 419/505 [03:03<00:37,  2.30it/s]$BRK.B: possibly delisted; no price data found  (period=1mo) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BRK.B: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "Fetching stock data...:  87%|████████▋ | 440/505 [03:15<00:30,  2.11it/s]$VRSK: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  87%|████████▋ | 441/505 [03:16<00:42,  1.52it/s]$IR: possibly delisted; no price data found  (period=1mo)\n",
      "$IR: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  88%|████████▊ | 442/505 [03:18<01:16,  1.22s/it]$GILD: possibly delisted; no price data found  (period=1mo)\n",
      "$GILD: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  88%|████████▊ | 443/505 [03:21<01:33,  1.51s/it]$LULU: possibly delisted; no price data found  (period=1mo)\n",
      "$LULU: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  88%|████████▊ | 444/505 [03:25<02:20,  2.30s/it]$SYK: possibly delisted; no price data found  (period=1mo)\n",
      "$SYK: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  88%|████████▊ | 445/505 [03:27<02:23,  2.40s/it]$SWKS: possibly delisted; no price data found  (period=1mo)\n",
      "$SWKS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  88%|████████▊ | 446/505 [03:30<02:17,  2.33s/it]$AMD: possibly delisted; no price data found  (period=1mo)\n",
      "$AMD: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  89%|████████▊ | 447/505 [03:32<02:11,  2.27s/it]$AEE: possibly delisted; no price data found  (period=1mo)\n",
      "$AEE: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  89%|████████▊ | 448/505 [03:34<02:08,  2.26s/it]$IDXX: possibly delisted; no price data found  (period=1mo)\n",
      "$IDXX: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  89%|████████▉ | 449/505 [03:36<02:01,  2.17s/it]$HUBB: possibly delisted; no price data found  (period=1mo)\n",
      "$HUBB: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  89%|████████▉ | 450/505 [03:38<01:54,  2.09s/it]$TMUS: possibly delisted; no price data found  (period=1mo)\n",
      "$TMUS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  89%|████████▉ | 451/505 [03:40<01:51,  2.07s/it]$MDLZ: possibly delisted; no price data found  (period=1mo)\n",
      "$MDLZ: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|████████▉ | 452/505 [03:42<01:54,  2.15s/it]$CHRW: possibly delisted; no price data found  (period=1mo)\n",
      "$CHRW: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|████████▉ | 453/505 [03:44<01:46,  2.05s/it]$GEN: possibly delisted; no price data found  (period=1mo)\n",
      "$GEN: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|████████▉ | 454/505 [03:46<01:51,  2.18s/it]$TER: possibly delisted; no price data found  (period=1mo)\n",
      "$TER: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|█████████ | 455/505 [03:49<01:50,  2.22s/it]$ROL: possibly delisted; no price data found  (period=1mo)\n",
      "$ROL: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|█████████ | 456/505 [03:51<01:46,  2.17s/it]$DOC: possibly delisted; no price data found  (period=1mo)\n",
      "$DOC: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  90%|█████████ | 457/505 [03:53<01:46,  2.21s/it]$OKE: possibly delisted; no price data found  (period=1mo)\n",
      "$OKE: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  91%|█████████ | 458/505 [03:55<01:40,  2.14s/it]$UAL: possibly delisted; no price data found  (period=1mo)\n",
      "$UAL: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  91%|█████████ | 459/505 [03:57<01:37,  2.11s/it]$LIN: possibly delisted; no price data found  (period=1mo)\n",
      "$LIN: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  91%|█████████ | 460/505 [03:59<01:37,  2.16s/it]$BAX: possibly delisted; no price data found  (period=1mo)\n",
      "$BAX: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  91%|█████████▏| 461/505 [04:01<01:31,  2.09s/it]$DELL: possibly delisted; no price data found  (period=1mo)\n",
      "$DELL: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  91%|█████████▏| 462/505 [04:03<01:29,  2.08s/it]$MS: possibly delisted; no price data found  (period=1mo)\n",
      "$MS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  92%|█████████▏| 463/505 [04:05<01:25,  2.03s/it]$CNC: possibly delisted; no price data found  (period=1mo)\n",
      "$CNC: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  92%|█████████▏| 464/505 [04:07<01:23,  2.03s/it]$SPGI: possibly delisted; no price data found  (period=1mo)\n",
      "$SPGI: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  92%|█████████▏| 465/505 [04:09<01:18,  1.97s/it]$MAS: possibly delisted; no price data found  (period=1mo)\n",
      "$MAS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  92%|█████████▏| 466/505 [04:11<01:18,  2.00s/it]$KEY: possibly delisted; no price data found  (period=1mo)\n",
      "$KEY: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  92%|█████████▏| 467/505 [04:13<01:13,  1.94s/it]$WEC: possibly delisted; no price data found  (period=1mo)\n",
      "$WEC: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  93%|█████████▎| 468/505 [04:15<01:10,  1.89s/it]$WAT: possibly delisted; no price data found  (period=1mo)\n",
      "$WAT: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  93%|█████████▎| 469/505 [04:17<01:08,  1.91s/it]$WST: possibly delisted; no price data found  (period=1mo)\n",
      "$WST: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  93%|█████████▎| 470/505 [04:19<01:06,  1.90s/it]$CI: possibly delisted; no price data found  (period=1mo)\n",
      "$CI: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  93%|█████████▎| 471/505 [04:20<01:02,  1.84s/it]$AOS: possibly delisted; no price data found  (period=1mo)\n",
      "$AOS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  93%|█████████▎| 472/505 [04:22<01:01,  1.87s/it]$CFG: possibly delisted; no price data found  (period=1mo)\n",
      "$CFG: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  94%|█████████▎| 473/505 [04:24<00:58,  1.84s/it]$VTRS: possibly delisted; no price data found  (period=1mo)\n",
      "$VTRS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  94%|█████████▍| 474/505 [04:26<00:58,  1.88s/it]$DLTR: possibly delisted; no price data found  (period=1mo)\n",
      "$DLTR: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  94%|█████████▍| 475/505 [04:28<00:57,  1.92s/it]$WY: possibly delisted; no price data found  (period=1mo)\n",
      "$WY: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  94%|█████████▍| 476/505 [04:30<00:56,  1.95s/it]$PHM: possibly delisted; no price data found  (period=1mo)\n",
      "$PHM: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  94%|█████████▍| 477/505 [04:32<00:56,  2.02s/it]$CPRT: possibly delisted; no price data found  (period=1mo)\n",
      "$CPRT: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  95%|█████████▍| 478/505 [04:34<00:53,  1.96s/it]$PNW: possibly delisted; no price data found  (period=1mo)\n",
      "$PNW: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  95%|█████████▍| 479/505 [04:37<00:54,  2.11s/it]$COF: possibly delisted; no price data found  (period=1mo)\n",
      "$COF: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  95%|█████████▌| 480/505 [04:38<00:51,  2.05s/it]$STZ: possibly delisted; no price data found  (period=1mo)\n",
      "$STZ: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  95%|█████████▌| 481/505 [04:41<00:48,  2.04s/it]$MTB: possibly delisted; no price data found  (period=1mo)\n",
      "$MTB: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  95%|█████████▌| 482/505 [04:43<00:47,  2.09s/it]$RSG: possibly delisted; no price data found  (period=1mo)\n",
      "$RSG: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  96%|█████████▌| 483/505 [04:45<00:44,  2.03s/it]$BDX: possibly delisted; no price data found  (period=1mo)\n",
      "$BDX: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  96%|█████████▌| 484/505 [04:46<00:41,  1.97s/it]$PM: possibly delisted; no price data found  (period=1mo)\n",
      "$PM: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  96%|█████████▌| 485/505 [04:49<00:41,  2.08s/it]$NDSN: possibly delisted; no price data found  (period=1mo)\n",
      "$NDSN: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  96%|█████████▌| 486/505 [04:51<00:38,  2.02s/it]$AIG: possibly delisted; no price data found  (period=1mo)\n",
      "$AIG: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  96%|█████████▋| 487/505 [04:53<00:37,  2.10s/it]$NRG: possibly delisted; no price data found  (period=1mo)\n",
      "$NRG: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  97%|█████████▋| 488/505 [04:55<00:35,  2.07s/it]$TFX: possibly delisted; no price data found  (period=1mo)\n",
      "$TFX: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  97%|█████████▋| 489/505 [04:57<00:31,  1.96s/it]$UPS: possibly delisted; no price data found  (period=1mo)\n",
      "$UPS: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...:  97%|█████████▋| 490/505 [04:58<00:28,  1.90s/it]$VICI: possibly delisted; no price data found  (period=1mo)\n",
      "Fetching stock data...:  99%|█████████▉| 499/505 [05:04<00:02,  2.12it/s]$BF.B: possibly delisted; no price data found  (period=1mo)\n",
      "$BF.B: possibly delisted; no price data found  (period=1y)\n",
      "Fetching stock data...: 100%|██████████| 505/505 [05:06<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fetching stock data in 306.30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Fetch the data and prepare it for the VAE\n",
    "# ==============================================================================\n",
    "\n",
    "sp500_df = scrape_sp500_wikipedia()  # Use the function you created to scrape S&P 500 companies\n",
    "custom_tickers = ['TSLA', 'ZM', 'SNOW']  # Example custom tickers\n",
    "stock_data, sector_mapping, industry_mapping = fetch_stock_data(sp500_df, custom_tickers) # Fetch data\n",
    "stock_data_vae = prepare_data_for_vae(stock_data)  # Prepare data for VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 132])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Pre-processing for training \n",
    "# ==============================================================================\n",
    "\n",
    "stock_data= stock_data_vae.dropna()\n",
    "\n",
    "# Normalize the stock data\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(stock_data)\n",
    "\n",
    "# Convert the normalized data to PyTorch tensors\n",
    "tensor_data = torch.tensor(normalized_data, dtype=torch.float32)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(tensor_data)\n",
    "\n",
    "\n",
    "# Check the DataLoader output\n",
    "next(iter(train_loader))[0].shape  # Shape of one batch of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best parameters from file: {'latent_dim': 20, 'beta': 9.580590843212875, 'learning_rate': 0.0009313450742597483, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Hyper parameter tuning \n",
    "# ==============================================================================\n",
    "\n",
    "# Define the file path for storing the best parameters\n",
    "best_params_file = \"config/best_params.json\"\n",
    "\n",
    "# Check if the best_params file exists\n",
    "if os.path.exists(best_params_file):\n",
    "    # Load the best parameters from the file\n",
    "    with open(best_params_file, \"r\") as f:\n",
    "        best_params = json.load(f)\n",
    "    print(\"Loaded best parameters from file:\", best_params)\n",
    "else:\n",
    "    # File doesn't exist, run the Optuna study\n",
    "    print(\"Best parameters file not found. Running Optuna study...\")\n",
    "    \n",
    "    # Assuming `normalized_data_cleaned` is the prepared dataset\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, normalized_data), n_trials=50)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    print(\"Best hyperparameters found:\", best_params)\n",
    "\n",
    "    # Save the best parameters to a JSON file\n",
    "    os.makedirs(os.path.dirname(best_params_file), exist_ok=True)  # Create directory if it doesn't exist\n",
    "    with open(best_params_file, \"w\") as f:\n",
    "        json.dump(best_params, f, indent=4)\n",
    "    print(f\"Best parameters saved to {best_params_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found at models/beta_vae_with_metadata.pth. Training a new model...\n",
      "Epoch [1/50], Training Loss: 145.9093\n",
      "Epoch [1/50], Validation Loss: 186.8883\n",
      "Epoch [2/50], Training Loss: 126.2666\n",
      "Epoch [2/50], Validation Loss: 182.0970\n",
      "Epoch [3/50], Training Loss: 124.6892\n",
      "Epoch [3/50], Validation Loss: 181.9565\n",
      "Epoch [4/50], Training Loss: 124.6597\n",
      "Epoch [4/50], Validation Loss: 181.9396\n",
      "Epoch [5/50], Training Loss: 124.6546\n",
      "Epoch [5/50], Validation Loss: 181.9319\n",
      "Epoch [6/50], Training Loss: 124.6488\n",
      "Epoch [6/50], Validation Loss: 181.9266\n",
      "Epoch [7/50], Training Loss: 124.6478\n",
      "Epoch [7/50], Validation Loss: 181.9399\n",
      "Epoch [8/50], Training Loss: 124.6441\n",
      "Epoch [8/50], Validation Loss: 181.9349\n",
      "Epoch [9/50], Training Loss: 124.6381\n",
      "Epoch [9/50], Validation Loss: 181.9391\n",
      "Epoch [10/50], Training Loss: 124.6420\n",
      "Epoch [10/50], Validation Loss: 181.9688\n",
      "Epoch [11/50], Training Loss: 124.6514\n",
      "Epoch [11/50], Validation Loss: 181.9538\n",
      "Epoch [12/50], Training Loss: 124.6360\n",
      "Epoch [12/50], Validation Loss: 181.9511\n",
      "Epoch [13/50], Training Loss: 124.6413\n",
      "Epoch [13/50], Validation Loss: 181.9486\n",
      "Epoch [14/50], Training Loss: 124.6401\n",
      "Epoch [14/50], Validation Loss: 181.9846\n",
      "Epoch [15/50], Training Loss: 124.6334\n",
      "Epoch [15/50], Validation Loss: 181.9914\n",
      "Epoch [16/50], Training Loss: 124.6442\n",
      "Epoch [16/50], Validation Loss: 182.0056\n",
      "Epoch [17/50], Training Loss: 124.6471\n",
      "Epoch [17/50], Validation Loss: 181.9629\n",
      "Epoch [18/50], Training Loss: 124.6378\n",
      "Epoch [18/50], Validation Loss: 181.9554\n",
      "Epoch [19/50], Training Loss: 124.6345\n",
      "Epoch [19/50], Validation Loss: 181.9896\n",
      "Epoch [20/50], Training Loss: 124.6182\n",
      "Epoch [20/50], Validation Loss: 182.0091\n",
      "Epoch [21/50], Training Loss: 124.6388\n",
      "Epoch [21/50], Validation Loss: 182.0383\n",
      "Epoch [22/50], Training Loss: 124.6364\n",
      "Epoch [22/50], Validation Loss: 182.0354\n",
      "Epoch [23/50], Training Loss: 124.6457\n",
      "Epoch [23/50], Validation Loss: 181.9960\n",
      "Epoch [24/50], Training Loss: 124.6297\n",
      "Epoch [24/50], Validation Loss: 182.0064\n",
      "Epoch [25/50], Training Loss: 124.6401\n",
      "Epoch [25/50], Validation Loss: 182.0154\n",
      "Epoch [26/50], Training Loss: 124.6298\n",
      "Epoch [26/50], Validation Loss: 182.0660\n",
      "Epoch [27/50], Training Loss: 124.6205\n",
      "Epoch [27/50], Validation Loss: 182.0841\n",
      "Epoch [28/50], Training Loss: 124.6117\n",
      "Epoch [28/50], Validation Loss: 182.0688\n",
      "Epoch [29/50], Training Loss: 124.6357\n",
      "Epoch [29/50], Validation Loss: 182.0474\n",
      "Epoch [30/50], Training Loss: 124.6241\n",
      "Epoch [30/50], Validation Loss: 182.0568\n",
      "Epoch [31/50], Training Loss: 124.6229\n",
      "Epoch [31/50], Validation Loss: 182.0976\n",
      "Epoch [32/50], Training Loss: 124.6275\n",
      "Epoch [32/50], Validation Loss: 182.0824\n",
      "Epoch [33/50], Training Loss: 124.6365\n",
      "Epoch [33/50], Validation Loss: 182.0719\n",
      "Epoch [34/50], Training Loss: 124.6307\n",
      "Epoch [34/50], Validation Loss: 182.0651\n",
      "Epoch [35/50], Training Loss: 124.6099\n",
      "Epoch [35/50], Validation Loss: 182.0787\n",
      "Epoch [36/50], Training Loss: 124.5984\n",
      "Epoch [36/50], Validation Loss: 182.1146\n",
      "Epoch [37/50], Training Loss: 124.6534\n",
      "Epoch [37/50], Validation Loss: 182.1127\n",
      "Epoch [38/50], Training Loss: 124.5916\n",
      "Epoch [38/50], Validation Loss: 182.0653\n",
      "Epoch [39/50], Training Loss: 124.6406\n",
      "Epoch [39/50], Validation Loss: 182.1069\n",
      "Epoch [40/50], Training Loss: 124.6262\n",
      "Epoch [40/50], Validation Loss: 182.0976\n",
      "Epoch [41/50], Training Loss: 124.6375\n",
      "Epoch [41/50], Validation Loss: 182.1162\n",
      "Epoch [42/50], Training Loss: 124.6140\n",
      "Epoch [42/50], Validation Loss: 182.0799\n",
      "Epoch [43/50], Training Loss: 124.6290\n",
      "Epoch [43/50], Validation Loss: 182.1210\n",
      "Epoch [44/50], Training Loss: 124.6477\n",
      "Epoch [44/50], Validation Loss: 182.2164\n",
      "Epoch [45/50], Training Loss: 124.6117\n",
      "Epoch [45/50], Validation Loss: 182.1159\n",
      "Epoch [46/50], Training Loss: 124.5929\n",
      "Epoch [46/50], Validation Loss: 182.2030\n",
      "Epoch [47/50], Training Loss: 124.5517\n",
      "Epoch [47/50], Validation Loss: 182.3076\n",
      "Epoch [48/50], Training Loss: 124.5562\n",
      "Epoch [48/50], Validation Loss: 182.1544\n",
      "Epoch [49/50], Training Loss: 124.4762\n",
      "Epoch [49/50], Validation Loss: 182.0840\n",
      "Epoch [50/50], Training Loss: 124.3728\n",
      "Epoch [50/50], Validation Loss: 182.2614\n",
      "Model trained and saved to models/beta_vae_with_metadata.pth.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Load or train the model\n",
    "# ==============================================================================\n",
    "\n",
    "# File path for the saved model\n",
    "model_path = \"models/beta_vae_with_metadata.pth\"\n",
    "\n",
    "# Check if the model file exists\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Model found at {model_path}. Loading the model...\")\n",
    "\n",
    "    # Load model state and metadata\n",
    "    model_metadata = torch.load(model_path)\n",
    "\n",
    "    # Recreate the model using the saved metadata\n",
    "    beta_vae = BetaVAE(\n",
    "        input_dim=model_metadata[\"input_dim\"],\n",
    "        latent_dim=model_metadata[\"latent_dim\"],\n",
    "        beta=model_metadata[\"beta\"]\n",
    "    )\n",
    "    beta_vae.load_state_dict(model_metadata[\"model_state\"])\n",
    "    beta_vae.eval()  # Set the model to evaluation mode\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Model not found at {model_path}. Training a new model...\")\n",
    "\n",
    "    # Assuming you use the best hyperparameters from Optuna\n",
    "    latent_dim = best_params['latent_dim']\n",
    "    beta = best_params['beta']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    batch_size = best_params['batch_size']\n",
    "    input_dim = stock_data.shape[1]\n",
    "\n",
    "    # Recreate DataLoaders with the best batch size\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(tensor_data, batch_size=batch_size)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    beta_vae = BetaVAE(input_dim=input_dim, latent_dim=latent_dim, beta=beta)\n",
    "    train_beta_vae(beta_vae, train_loader, val_loader, num_epochs=50, learning_rate=learning_rate)\n",
    "\n",
    "    # Save the trained model with metadata\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)  # Ensure the directory exists\n",
    "    model_metadata = {\n",
    "        \"model_state\": beta_vae.state_dict(),\n",
    "        \"input_dim\": input_dim,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"beta\": beta\n",
    "    }\n",
    "    torch.save(model_metadata, model_path)\n",
    "    print(f\"Model trained and saved to {model_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Embeddings Shape: tensor([[ 0.9302, -0.8676,  1.2323,  ..., -0.4505,  0.4879,  0.3029],\n",
      "        [ 0.9287, -0.2542,  0.6318,  ..., -0.5965,  1.4383,  0.5167],\n",
      "        [ 0.2162,  0.6953, -0.8736,  ...,  0.3986, -0.8824, -1.0187],\n",
      "        ...,\n",
      "        [-0.6109, -0.8155, -1.5960,  ...,  2.5134,  0.3669,  0.4822],\n",
      "        [ 0.6337,  0.1730,  1.1927,  ...,  0.8057,  0.2487,  0.9620],\n",
      "        [-0.5940, -0.4366,  0.9972,  ..., -0.4368, -0.4953, -1.4547]])\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings for the training data\n",
    "train_embeddings = get_embeddings(beta_vae, train_loader)\n",
    "\n",
    "# Optionally, extract embeddings for validation and test data\n",
    "val_embeddings = get_embeddings(beta_vae, val_loader)\n",
    "test_embeddings = get_embeddings(beta_vae, test_loader)\n",
    "\n",
    "print(\"Train Embeddings Shape:\", train_embeddings)  # Should be (num_samples, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
